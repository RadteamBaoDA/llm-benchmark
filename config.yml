# LLM Benchmark Tool Configuration

# API Configuration
api:
  base_url: "http://localhost:8000"
  api_key: ""  # Or use environment variable OPENAI_API_KEY
  timeout: 60

# Model Configuration
model:
  name: "BAAI/bge-reranker-v2-m3"
  type: "reranker"  # Options: chat, embed, reranker, vision
  max_tokens: 1024
  temperature: 0.2

# Mock Data Configuration (used for generating benchmark requests)
mock_data:
  # Chat model prompts
  chat_prompts:
    - "Hello, world!"
    - "What is the capital of France?"
    - "Explain quantum computing in simple terms."
    - "Write a haiku about programming."
    - "What are the benefits of exercise?"
  
  # Embedding texts
  embed_texts:
    - "The quick brown fox jumps over the lazy dog."
    - "Machine learning is a subset of artificial intelligence."
    - "Python is a popular programming language."
    - "Natural language processing enables computers to understand text."
    - "Deep learning models require large amounts of data."
  
  # Reranker configuration
  reranker_documents:
    - "Machine learning is a type of artificial intelligence that allows computers to learn from data."
    - "The weather today is sunny with a high of 75 degrees."
    - "Python is commonly used for machine learning applications."
    - "Machine learning algorithms can identify patterns in large datasets."
    - "Coffee is one of the most popular beverages in the world."
    - "Deep learning models use neural networks with many layers."
    - "Data preprocessing and cleaning improve model quality."
    - "Feature engineering can significantly improve model performance."
    - "Supervised learning relies on labeled datasets for training."
    - "Unsupervised learning techniques discover hidden structures."
    - "Overfitting occurs when a model learns noise instead of signal."
    - "Gradient descent is a common optimization algorithm for training models."
    - "Decision trees provide interpretable predictions and rules."
    - "Reinforcement learning trains agents through rewards and penalties."
    - "Data scientists often use Python, R, and SQL to analyze data."
  
  # Vision model configuration
  vision_prompts:
    - "Describe this image in detail."
    - "What objects can you see in this image?"
    - "What is the main subject of this image?"
  vision_image_url: "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg"
  # vision_image_base64: null  # Optional: base64 encoded image
  # vision_image_path: null  # Optional: single local image path (e.g., "./images/test.jpg")
  # vision_image_paths:  # Optional: multiple local image paths (cycles through them)
  #   - "./images/image1.jpg"
  #   - "./images/image2.png"
  #   - "./images/image3.webp"

# Logging Configuration
# Enable debug logging to diagnose request failures
logging:
  level: "DEBUG"  # DEBUG, INFO, WARNING, ERROR
  log_requests: true  # Log HTTP request details (URL, headers, payload)
  log_responses: true  # Log HTTP response details (status, body)
  log_file: null  # Log file path (null = console only, e.g., "benchmark.log")
  max_payload_length: 500  # Truncate payload in logs (characters)
  max_response_length: 500  # Truncate response body in logs (characters)

# Scenario Configuration
# Scenarios are defined in a separate file for better organization
scenario_file: "scenario.yml"

# Benchmark Settings
benchmark:
  default_requests: 100
  default_concurrency: 10
  capture_responses: false
  output_dir: "results"
  export_formats:
    - "markdown"
    - "csv"
  quiet: false
